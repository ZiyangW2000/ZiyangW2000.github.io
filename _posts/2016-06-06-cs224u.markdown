---
layout: post
title:  "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation"
date:   2025-06-20 22:21:59 +00:00
image: /images/mexa.png
categories: research
author: "Shoubin Yu, Yue Zhang, Ziyang Wang, Jaehong Yoon, Mohit Bansal"
authors: "Shoubin Yu*, Yue Zhang*, <strong>Ziyang Wang</strong>, Jaehong Yoon, Mohit Bansal"
venue: "EMNLP 2025 Findings"
arxiv: https://arxiv.org/abs/2506.17113
code: https://github.com/Yui010206/MEXA
---
We introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains.
